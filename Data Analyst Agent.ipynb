{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68ed87c5-40a1-4541-9841-b947104392fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.tools import google_search, AgentTool, ToolContext\n",
    "from google.adk.code_executors import BuiltInCodeExecutor\n",
    "from google.adk.sessions import DatabaseSessionService\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "608920d3-67f0-49e5-a10e-ad58e3d28562",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ApiKey: ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"]=getpass(\"ApiKey:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caebc4e3-54cd-4c0e-98c2-7cb0b8391087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41cbf419-f573-4236-a658-60660b4cd745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tool for read the CSV and inspect for missing values\n",
    "def analyze_missing_data(df_path:str)->dict:\n",
    "    \"\"\"\n",
    "    Reads a CSV file into a pandas DataFrame, prints the total number of rows \n",
    "    and columns, and returns a detailed dictionary summary of missing (NaN) values \n",
    "    for every column that has them. Returns \"No missing values found.\" if clean.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df=pd.read_csv(df_path)\n",
    "        \n",
    "        #Calculate missing data sum\n",
    "        missing_data=df.isnull().sum()\n",
    "        missing_data=missing_data[missing_data>0]\n",
    "\n",
    "        missing_dict=missing_data.to_dict()\n",
    "        \n",
    "        if missing_data.empty:\n",
    "            return {\n",
    "                \"status\":\"success\",\n",
    "                \"message\":\"No missing values found.\",\n",
    "                \"missing_data\":{}\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"status\":\"success\",\n",
    "                \"message\":\"Missing values detected\",\n",
    "                \"missing_data\": missing_dict,\n",
    "                \"total_rows\":len(df)\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\":\"error\",\n",
    "            \"message\":str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1222b3d0-9c05-414b-aebf-7aaa375ec473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tool to fill missing values using the mean\n",
    "def impute_data_with_mean(df_path:str,column_name:str)->dict:\n",
    "    \"\"\"\n",
    "    Loads the CSV file, fills missing values (NaNs) in the specified column \n",
    "    with the mean of that column, and saves the modified DataFrame back \n",
    "    to the original path. Reports the result and the new missing count.\n",
    "    \n",
    "    Args:\n",
    "        df_path: Path to the CSV file (e.g., 'data/train.csv').\n",
    "        column_name: The column in which to fill NaNs.\n",
    "        \n",
    "    Returns:\n",
    "        A dict confirming the imputation result.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        πrint(f\"DEBUG: Trying to read {df_path}...\")\n",
    "        df=pd.read_csv(df_path)\n",
    "        \n",
    "        if column_name not in df.columns:\n",
    "            return {\n",
    "                \"status\":\"error\",\n",
    "                \"message\":f\"Column '{column_name}' not found in dataset\"\n",
    "            }\n",
    "\n",
    "        #Calculate mean and impute\n",
    "        impute_value=df[column_name].mean()\n",
    "        initial_missing_count=df[column_name].isnull().sum()\n",
    "        df[column_name]=df[column_name].fillna(impute_value)\n",
    "    \n",
    "        #Save back to the original path\n",
    "        df.to_csv(df_path,index=False)\n",
    "        final_missing_count=df[column_name].isnull().sum()\n",
    "        \n",
    "        return {\n",
    "            \"status\":\"success\",\n",
    "            \"column\":column_name,\n",
    "            \"imputed_value\":impute_value,\n",
    "            \"filled_count\":initial_missing_count,\n",
    "            \"message\":f\"Successfully filled {initial_missing} missing values with mean: {impute_value:.2f}\"\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\":\"error\",\n",
    "            \"message\":str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7072f07f-e9c2-4fad-a8f2-9fac8d37aac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0575ee25-0d0d-4f47-8695-877e5b7e12f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "# Custom tool to execute code and return a DICT\n",
    "def execute_python_code(code: str) -> dict:\n",
    "    \"\"\"\n",
    "    Executes Python code and returns the output (stdout) or error in a structured dictionary.\n",
    "    Useful for calculating stats, filtering data, or creating plots.\n",
    "    \"\"\"\n",
    "    # Capture standard output (print statements)\n",
    "    old_stdout = sys.stdout\n",
    "    redirected_output = StringIO()\n",
    "    sys.stdout = redirected_output\n",
    "\n",
    "    try:\n",
    "        # Execute the code\n",
    "        # Note: We use a shared dictionary for variables if you want state to persist, \n",
    "        # but for simple tasks 'locals()' or a new dict is safer.\n",
    "        exec(code, globals())\n",
    "        \n",
    "        # Get the output\n",
    "        sys.stdout = old_stdout\n",
    "        output = redirected_output.getvalue()\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"code_executed\": code,\n",
    "            \"output\": output if output else \"Code executed successfully (no output).\",\n",
    "            \"message\": \"Code ran without errors.\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        sys.stdout = old_stdout\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error_type\": type(e).__name__,\n",
    "            \"message\": str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "651118d7-12ca-41a3-a08f-a23b1f656163",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analyst_agent = LlmAgent(\n",
    "    name=\"DataAnalyst\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"You are an expert Data Analyst and data cleaning specialist. \n",
    "        Your primary goal is to inspect CSV files for missing data and suggest/execute \n",
    "        the best method to fill them, always prioritizing data integrity. \n",
    "        You must use the 'analyze_missing_data' tool first when asked about data quality.\n",
    "    \"\"\",\n",
    "    tools=[analyze_missing_data,impute_data_with_mean,execute_python_code],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4222b9af-acc4-481f-9429-586c80039d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2c603ca-e356-45e8-b684-899f6f5a1873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fc10794-b8fb-4887-92b4-587c9355516d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Agent Running ---\n",
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > Check 'train.csv' for missing values. If you find any in 'Age', fill them with the mean.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataAnalyst > It looks like there was an error in my last attempt, and I couldn't fill the missing 'Age' values. I'll try that again, and this time it should work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "<string>:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataAnalyst > It seems I'm having trouble with that command. I'll try a different approach to fill the missing 'Age' values.\n",
      "DataAnalyst > I've filled the missing values in the 'Age' column with the mean. Let me know if there's anything else you need!\n"
     ]
    }
   ],
   "source": [
    "runner = InMemoryRunner(agent=data_analyst_agent)\n",
    "\n",
    "\n",
    "file_path = 'train.csv' \n",
    "print(\"--- Agent Running ---\")\n",
    "\n",
    "\n",
    "_ = await runner.run_debug(\n",
    "    f\"Check '{file_path}' for missing values. If you find any in 'Age', fill them with the mean.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4eeeac14-c4b2-451e-b2ef-b973c5bcaa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          891 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d9a601-8bf3-4d9f-bc08-469ae3c5e324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
